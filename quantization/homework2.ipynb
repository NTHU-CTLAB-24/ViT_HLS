{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "04a61290"
      },
      "source": [
        "# HW2: Model Inference of the Pretrained LeNet"
      ],
      "id": "04a61290"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2a9c9ccd"
      },
      "source": [
        "<font color='red'>Name: (Replace with your name) Student ID: (Replace with your Student ID) </font>"
      ],
      "id": "2a9c9ccd"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hgOV5ADgHGeO"
      },
      "source": [
        "## 1. Data preparation\n"
      ],
      "id": "hgOV5ADgHGeO"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Build a QAT network (with our customized configuration) and train."
      ],
      "metadata": {
        "id": "FVxTIHHc6V5I"
      },
      "id": "FVxTIHHc6V5I"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-UBDWLzcKFXH"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from collections import OrderedDict\n",
        "import numpy as np\n",
        "import random\n",
        "seed = 0\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed_all(seed)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "id": "-UBDWLzcKFXH"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CzK6ohj5oNCT"
      },
      "outputs": [],
      "source": [
        "def train(model: nn.Module, dataloader: DataLoader, num_epoch):\n",
        "    \n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "    for epoch in range(num_epoch):  # loop over the dataset multiple times\n",
        "\n",
        "        running_loss = 0.0\n",
        "        for i, data in enumerate(dataloader):\n",
        "            \n",
        "            inputs, labels = data[0].to(device), data[1].to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss = loss.requires_grad_()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # print statistics\n",
        "            running_loss += loss.item()\n",
        "            if i % 50 == 49:    # print every 2000 mini-batches\n",
        "                print('[%d, %5d] loss: %.3f' %\n",
        "                    (epoch + 1, i + 1, running_loss / 2000))\n",
        "                running_loss = 0.0\n",
        "        print(test(model, testloader, None))\n",
        "    print('Finished Training')\n",
        "    \n",
        "def test(model: nn.Module, dataloader: DataLoader, max_samples=None) -> float:\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    n_inferences = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for data in dataloader:\n",
        "            \n",
        "            inputs, labels = data[0].to(device), data[1].to(device)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "            if max_samples:\n",
        "                n_inferences += inputs.shape[0]\n",
        "                if n_inferences > max_samples:\n",
        "                    break\n",
        "    \n",
        "    return 100 * correct / total\n",
        "\n"
      ],
      "id": "CzK6ohj5oNCT"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "edyil7YyfBHS"
      },
      "outputs": [],
      "source": [
        "class LeNet5QAT(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(LeNet5QAT, self).__init__()\n",
        "        self.conv1 = nn.Sequential(OrderedDict([\n",
        "            ('conv', nn.Conv2d(1, 6, 5, bias=False)),\n",
        "            ('relu', nn.ReLU()),\n",
        "        ]))\n",
        "        \n",
        "        self.maxpool2 = nn.Sequential(OrderedDict([\n",
        "            ('pool', nn.MaxPool2d(kernel_size=(2, 2), stride=2))\n",
        "        ]))\n",
        "        \n",
        "        self.conv3 = nn.Sequential(OrderedDict([\n",
        "            ('conv', nn.Conv2d(6, 16, 5, bias=False)),\n",
        "            ('relu', nn.ReLU())\n",
        "        ]))\n",
        "        \n",
        "        self.maxpool4 = nn.Sequential(OrderedDict([\n",
        "            ('pool', nn.MaxPool2d(kernel_size=(2, 2), stride=2))\n",
        "        ]))\n",
        "        \n",
        "        self.conv5 = nn.Sequential(OrderedDict([\n",
        "            ('conv', nn.Conv2d(16, 120, 5, bias=False)),\n",
        "            ('relu', nn.ReLU())\n",
        "        ]))\n",
        "        \n",
        "        self.fc6 = nn.Sequential(OrderedDict([\n",
        "            ('fc', nn.Linear(120, 84, bias=False)),\n",
        "            ('relu', nn.ReLU())\n",
        "        ]))\n",
        "        \n",
        "        self.output = nn.Sequential(OrderedDict([\n",
        "            ('fc', nn.Linear(84, 10, bias=True)),\n",
        "        ]))\n",
        "        \n",
        "        self.quant = quant.QuantStub()\n",
        "        self.dequant = quant.DeQuantStub()\n",
        "        \n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.quant(x)\n",
        "        x = self.conv1(x)\n",
        "        x = self.maxpool2(x)\n",
        "        x = self.conv3(x)\n",
        "        x = self.maxpool4(x)\n",
        "        x = self.conv5(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.fc6(x)\n",
        "        x = self.output(x)\n",
        "        x = self.dequant(x)\n",
        "        \n",
        "        return x\n"
      ],
      "id": "edyil7YyfBHS"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YaWiXKyWlH2-"
      },
      "outputs": [],
      "source": [
        "qcfg = torch.quantization.get_default_qat_qconfig('qnnpack')\n",
        "qact = torch.quantization.FakeQuantize.with_args(observer=torch.quantization.MovingAverageMinMaxObserver,\n",
        "                             quant_min=-128, quant_max=127, dtype=torch.qint8,\n",
        "                             qscheme=torch.per_tensor_symmetric, reduce_range=False)\n",
        "qcfg = torch.quantization.QConfig(activation=qact, weight=qcfg.weight)"
      ],
      "id": "YaWiXKyWlH2-"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xvIGP5YNiDA0"
      },
      "outputs": [],
      "source": [
        "def seed_worker(worker_id):\n",
        "    worker_seed = torch.initial_seed() % 2**32\n",
        "    np.random.seed(worker_seed)\n",
        "    random.seed(worker_seed)\n",
        "\n",
        "g = torch.Generator()\n",
        "g.manual_seed(0)\n",
        "\n",
        "transform = transforms.Compose(\n",
        "    [\n",
        "     transforms.Resize((32, 32)),\n",
        "     transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5,), (0.5,))\n",
        "    ])\n",
        "\n",
        "trainset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4, shuffle=True, num_workers=2, worker_init_fn=seed_worker, generator=g,)\n",
        "\n",
        "testset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=8, shuffle=False, num_workers=2, worker_init_fn=seed_worker, generator=g,)"
      ],
      "id": "xvIGP5YNiDA0"
    },
    {
      "cell_type": "markdown",
      "source": [
        "* You should comment out `train(model, trainloader, 1)` and uncomment `model.load_state_dict(torch.load('qat_prepare.pt'))` before submitting your homework.\n",
        "    * Also, reloading the model from `qat_prepare.pt` can save your time if there is something wrong and you need to restart and run all."
      ],
      "metadata": {
        "id": "wPY1BNZzZ6or"
      },
      "id": "wPY1BNZzZ6or"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1k1P3SAifHPV"
      },
      "outputs": [],
      "source": [
        "import torch.quantization as quant\n",
        "\n",
        "# define the model\n",
        "model = LeNet5QAT().to(device)\n",
        "\n",
        "# define the loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# prepare the model for QAT\n",
        "model.train()\n",
        "torch.backends.quantized.engine = 'qnnpack'\n",
        "model.qconfig = qcfg\n",
        "torch.quantization.prepare_qat(model, inplace=True)\n",
        "\n",
        "# model.load_state_dict(torch.load('qat_prepare.pt'))\n",
        "train(model, trainloader, 1)\n",
        "torch.save(model.state_dict(), 'qat_prepare.pt')\n",
        "\n",
        "# convert the model to a quantized model\n",
        "torch.quantization.convert(model, inplace=True)\n",
        "\n",
        "# evaluate the model on the test set\n",
        "model.eval()\n",
        "\n",
        "\n",
        "device=torch.device('cpu')\n",
        "score = test(model, testloader)\n",
        "print('Accuracy of the quantized LeNet-5 model on the test images: {}%'.format(score))"
      ],
      "id": "1k1P3SAifHPV"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Extract weight, floating-point bias and floating-point scale of activations and weights of every layer."
      ],
      "metadata": {
        "id": "dUH4mYi552tW"
      },
      "id": "dUH4mYi552tW"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WSIdYFyZshFj"
      },
      "outputs": [],
      "source": [
        "import os \n",
        "import zipfile\n",
        "# It is easier to download all the files with zip\n",
        "zf = zipfile.ZipFile('parameters.zip', 'w', zipfile.ZIP_DEFLATED)"
      ],
      "id": "WSIdYFyZshFj"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "27MD_hJUzlnf"
      },
      "outputs": [],
      "source": [
        "if not os.path.exists('./weights'):\n",
        "    os.mkdir('./weights')\n",
        "if not os.path.exists('./float_scale'):\n",
        "    os.mkdir('./float_scale')\n",
        "    \n",
        "for name, weights in model.state_dict().items():\n",
        "    name_split = name.split('.')\n",
        "    if(weights!= None):\n",
        "      if(name_split[-2] != \"_packed_params\"):\n",
        "        if(weights.type()== \"torch.quantized.QInt8Tensor\" or weights.type()== \"torch.quantized.QUInt8Tensor\"):\n",
        "          np.savetxt('./weights/%s.csv' %(name) , weights.cpu().int_repr().numpy().reshape(-1).astype(float), delimiter=',')\n",
        "          zf.write('./weights/%s.csv' %(name))\n",
        "\n",
        "          np.savetxt('./float_scale/%s.scale.csv' %(name) , np.array([weights.q_scale()]), delimiter=',')\n",
        "\n",
        "          np.savetxt('./float_scale/%s.zero_point.csv' %(name) , np.array([weights.q_scale()]), delimiter=',')\n",
        "        else:\n",
        "          np.savetxt('./float_scale/%s.csv' %(name) , weights.cpu().numpy().reshape(-1).astype(float), delimiter=',')\n",
        "\n",
        "      elif(name_split[-1] == \"_packed_params\"):\n",
        "        if not os.path.exists('./weights/_packed_params'):\n",
        "          os.mkdir('./weights/_packed_params')\n",
        "        name = name_split[0]+\".\"+name_split[1]\n",
        "        weight, bias = weights\n",
        "        if(weight.type()== \"torch.quantized.QInt8Tensor\" or weight.type()== \"torch.quantized.QUInt8Tensor\"):\n",
        "          np.savetxt('./weights/%s.weight.csv' %(name)  , weight.cpu().int_repr().numpy().reshape(-1).astype(float), delimiter=',')\n",
        "          zf.write('./weights/%s.weight.csv' %(name))\n",
        "\n",
        "          np.savetxt('./float_scale/%s.weight.scale.csv' %(name) , np.array([weight.q_scale()]), delimiter=',')\n",
        "\n",
        "          np.savetxt('./float_scale/%s.weight.zero_point.csv' %(name) , np.array([weight.q_zero_point()]), delimiter=',')\n",
        "        \n",
        "        if(bias != None):\n",
        "          \n",
        "          if(bias.type()== \"torch.quantized.QInt8Tensor\" or bias.type()== \"torch.quantized.QUInt8Tensor\"):\n",
        "            np.savetxt('./float_scale/%s.bias.csv' %(name) , bias.cpu().int_repr().numpy().reshape(-1).astype(float), delimiter=',')\n",
        "          else:\n",
        "            np.savetxt('./float_scale/%s.bias.csv' %(name) , bias.cpu().detach().numpy().reshape(-1).astype(float), delimiter=',')\n",
        "          "
      ],
      "id": "27MD_hJUzlnf"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.1 Caculate the fixed-point output scale of the QAT model\n",
        "In function `float_to_fixed_scale()`, first you need to calculate fixed-point scales $M_{l}$, which is something like $S_l$ in `homework1.ipynb`. Store them in the `scalesDict` dictionary. Second,  calculate a revised value for the `outputBias` variable.\n",
        "\n",
        "\n",
        "In the front, we extract the scales of input, output, and weight  for each layer from the model. By [pytorch Quantized Tensor](https://pytorch.org/docs/stable/quantization.html), the scaling factor of the input matrix $I_{l}$,  weight matrix $W_{l}$ and output matrix $O_{l}$ are denoted by $s_{W_{l}}$, $s_{I_{l}}$ and $s_{O_{l}}$ , respectively, for each layer ${l}$. The corresponding quantized 8-bit signed integer tensors are denoted by $I_{l_q}$, $W_{l_q}$ and $O_{l_q}$. Note that the definition here is a bit different from our `homework1.ipynb`:\n",
        "$$I_l = I_{l_q} * s_{I_{l}},$$\n",
        "$$W_l = W_{l_q} * s_{W_{l}},$$\n",
        "$$O_l = O_{l_q} * s_{O_{l}}.$$\n",
        "\n",
        "In `float_to_fixed_scale()` TODO, we need to caculate $M_{l}$ and save them in `scalesDict` where in layer $l$, \n",
        "$$W_{l_q}* I_{l_q} * M_{l} \\approx O_{l_q} = I_{{l+1}_q}$$\n",
        "As for the initial input, we need to caculate $M_{quant}$ where\n",
        "$$I_{initialInput} * M_{quant} \\approx O_{{initialInput}_q} = I_{{conv1.conv}_q}$$\n",
        "*   hint: `act_scalesDict[layerName]` store the output activation scale, i.e., $s_{O_{l}}$ in the above equation, and it is also the input activation scale of the next layer $s_{I_{l+1}}$.\n",
        "\n",
        "\n",
        "\n",
        "To simplify the hardware implementation, let's convert $M_{l}$ into integer by multiplying `2**16` and rounding it. As for the initial input, you can simply round it since $M_{quant}$ is much greater than 1.\n",
        "\n",
        "In addition, you need to adjust the `outputBias` value to ensure that it remains unchanged when we use $M_{output}$ for requantization."
      ],
      "metadata": {
        "id": "-Pu3d84O9kLF"
      },
      "id": "-Pu3d84O9kLF"
    },
    {
      "cell_type": "code",
      "source": [
        "def float_to_fixed_scale():\n",
        "    scalesDict = {}\n",
        "    act_scalesDict = {}\n",
        "    weight_scalesDict = {}\n",
        "    outputBias = []\n",
        "    \n",
        "    layerName = [\"conv1.conv\", \"conv3.conv\", \"conv5.conv\", \"fc6.fc\", \"output.fc\"] \n",
        "    for key in layerName:\n",
        "        Arr = np.loadtxt('./float_scale/'+key+\".weight.scale.csv\",\n",
        "                         delimiter=',').reshape(([1])).astype(float)\n",
        "        weight_scalesDict[key] = Arr\n",
        "\n",
        "        Arr = np.loadtxt('./float_scale/'+key+\".scale.csv\",\n",
        "                         delimiter=',').reshape(([1])).astype(float)\n",
        "        act_scalesDict[key] = Arr\n",
        "\n",
        "    act_scalesDict[\"quant\"] = np.loadtxt(\"./float_scale/quant.scale.csv\",\n",
        "                      delimiter=',').reshape(([1])).astype(float)\n",
        "    outputBias = np.loadtxt(\n",
        "        './float_scale/'+key+\".bias.csv\", delimiter=',').reshape(([1, 10])).astype(float)\n",
        "    \n",
        "    \n",
        "    scalesDictName = [\"quant\", \"conv1.conv\", \"conv3.conv\", \"conv5.conv\", \"fc6.fc\", \"output.fc\"] \n",
        "    \n",
        "    # TODO\n",
        "    \n",
        "\n",
        "    return scalesDict, outputBias\n"
      ],
      "metadata": {
        "id": "FeD2U8vqn8kS"
      },
      "id": "FeD2U8vqn8kS",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "scalesDict, outputBias = float_to_fixed_scale()\n",
        "with open('fixed_scale.json', 'w', newline='') as jsonfile:\n",
        "    json.dump(scalesDict, jsonfile)\n",
        "zf.write('./fixed_scale.json')\n",
        "\n",
        "\n",
        "np.savetxt('./weights/output.fc.bias.csv', outputBias, delimiter=',')\n",
        "zf.write('./weights/output.fc.bias.csv')"
      ],
      "metadata": {
        "id": "SD66CrxS44Tb"
      },
      "id": "SD66CrxS44Tb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Reconstruct the model with build-in function and extract the input and output of layer."
      ],
      "metadata": {
        "id": "FdYAITnPrKlX"
      },
      "id": "FdYAITnPrKlX"
    },
    {
      "cell_type": "code",
      "source": [
        "def getWeightAndScale():\n",
        "    weightsDict = {}\n",
        "    shapeDict = {\"conv1.conv\": [6, 1, 5, 5],\n",
        "                 \"conv3.conv\": [16, 6, 5, 5],\n",
        "                 \"conv5.conv\": [120, 16, 5, 5], \n",
        "                 \"fc6.fc\": [84, 120],\n",
        "                 \"output.fc\": [10, 84]\n",
        "                 }\n",
        "\n",
        "    for key in shapeDict:\n",
        "        Arr = np.loadtxt('./weights/'+key+\".weight.csv\",\n",
        "                         delimiter=',').astype(int)\n",
        "        shape = shapeDict[key]\n",
        "        Arr = Arr.reshape(([i for i in shape]))\n",
        "        weightsDict[key] = Arr\n",
        "\n",
        "    weightsDict[\"outputBias\"] = np.loadtxt(\n",
        "        './weights/'+key+\".bias.csv\", delimiter=',').reshape(([1, 10])).astype(float)\n",
        "    \n",
        "    scalesDict = {}\n",
        "    with open('fixed_scale.json') as json_file:\n",
        "        scalesDict = json.load(json_file)\n",
        "    for i in scalesDict:\n",
        "      scalesDict[i] = np.array([scalesDict[i]])\n",
        "\n",
        "    return weightsDict, scalesDict"
      ],
      "metadata": {
        "id": "4HGS4L7PDD76"
      },
      "id": "4HGS4L7PDD76",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class QAT(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(QAT, self).__init__()\n",
        "        self.weightsDict, self.scalesDict = getWeightAndScale()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(1, 6, 5, bias=False)\n",
        "        self.conv1.weight.data = torch.from_numpy(self.weightsDict[\"conv1.conv\"]).float()\n",
        "        \n",
        "        self.maxpool2 = nn.Sequential(OrderedDict([\n",
        "            ('pool', nn.MaxPool2d(kernel_size=(2, 2), stride=2))\n",
        "        ]))\n",
        "        \n",
        "        self.conv3 = nn.Conv2d(6, 16, 5, bias=False)\n",
        "        self.conv3.weight.data = torch.from_numpy(self.weightsDict[\"conv3.conv\"]).float()\n",
        "\n",
        "        self.maxpool4 = nn.Sequential(OrderedDict([\n",
        "            ('pool', nn.MaxPool2d(kernel_size=(2, 2), stride=2))\n",
        "        ]))\n",
        "        \n",
        "        self.conv5 = nn.Conv2d(16, 120, 5, bias=False)\n",
        "        self.conv5.weight.data = torch.from_numpy(self.weightsDict[\"conv5.conv\"]).float()\n",
        "\n",
        "        \n",
        "        self.fc6 = nn.Linear(120, 84, bias=False)\n",
        "        self.fc6.weight.data = torch.from_numpy(self.weightsDict[\"fc6.fc\"]).float()\n",
        "\n",
        "        self.output = nn.Linear(84, 10, bias=True)\n",
        "        self.output.weight.data = torch.from_numpy(self.weightsDict[\"output.fc\"]).float()\n",
        "        self.output.bias.data = torch.from_numpy(self.weightsDict[\"outputBias\"].reshape(1, 10)).float()\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = torch.clamp(torch.quantize_per_tensor(x, torch.from_numpy(1/self.scalesDict[\"quant\"]), \n",
        "                  torch.tensor(0), torch.qint32).int_repr(), -128, 127).float()\n",
        "        x = self.conv1(x)\n",
        "        x = torch.clamp(torch.quantize_per_tensor(x, torch.from_numpy(1/self.scalesDict[\"conv1.conv\"]), \n",
        "                  torch.tensor(0), torch.qint32).int_repr() >> 16, 0, 127).float() \n",
        "        x = self.maxpool2(x)\n",
        "        x = self.conv3(x)\n",
        "        x = torch.clamp(torch.quantize_per_tensor(x, torch.from_numpy(1/self.scalesDict[\"conv3.conv\"]), \n",
        "                  torch.tensor(0), torch.qint32).int_repr() >> 16, 0, 127).float() \n",
        "\n",
        "        x = self.maxpool4(x)\n",
        "        x = self.conv5(x)\n",
        "        x = torch.clamp(torch.quantize_per_tensor(x, torch.from_numpy(1/self.scalesDict[\"conv5.conv\"]), \n",
        "                  torch.tensor(0), torch.qint32).int_repr() >> 16, 0, 127).float()\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.fc6(x)\n",
        "        x = torch.clamp(torch.quantize_per_tensor(x, torch.from_numpy(1/self.scalesDict[\"fc6.fc\"]), \n",
        "                  torch.tensor(0), torch.qint32).int_repr() >> 16, 0, 127).float() \n",
        "              \n",
        "        x = self.output(x)\n",
        "        x = torch.clamp(torch.quantize_per_tensor(x, torch.from_numpy(1/self.scalesDict[\"output.fc\"]), \n",
        "                  torch.tensor(0), torch.qint32).int_repr() >> 16, -128, 127) \n",
        "            \n",
        "        \n",
        "        return x"
      ],
      "metadata": {
        "id": "p91Q13HFBLjk"
      },
      "id": "p91Q13HFBLjk",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you’ve done everything correctly, the accuracy degradation should be negligible(~1%)."
      ],
      "metadata": {
        "id": "YE-HRT-65GL3"
      },
      "id": "YE-HRT-65GL3"
    },
    {
      "cell_type": "code",
      "source": [
        "qat = QAT()\n",
        "score = test(qat, testloader)\n",
        "print('Accuracy of the network with fixed point scale: {}%'.format(score))"
      ],
      "metadata": {
        "id": "olV64N348TFo"
      },
      "id": "olV64N348TFo",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def visualize_activations(module, input, output):\n",
        "    if module.profile_activations == True:\n",
        "        module.inAct = input[0].cpu().reshape(-1)\n",
        "        module.outAct = output[0].cpu().reshape(-1)"
      ],
      "metadata": {
        "id": "Qe5aCOS45uwF"
      },
      "execution_count": null,
      "outputs": [],
      "id": "Qe5aCOS45uwF"
    },
    {
      "cell_type": "code",
      "source": [
        "# random choose images as the input and get the output\n",
        "np.random.seed(0)\n",
        "index = np.random.randint(0,len(trainset), size=100)\n",
        "index = range(100)"
      ],
      "metadata": {
        "id": "rRkBhpwu51xU"
      },
      "execution_count": null,
      "outputs": [],
      "id": "rRkBhpwu51xU"
    },
    {
      "cell_type": "code",
      "source": [
        "if not os.path.exists('./activations'):\n",
        "    os.mkdir('./activations')\n",
        "for ind in range(100):\n",
        "    if not os.path.exists('./activations/img{}'.format(ind)):\n",
        "        os.mkdir('./activations/img{}'.format(ind))\n",
        "\n",
        "    for name, model in qat.named_children():\n",
        "        model.profile_activations = True\n",
        "        model.register_forward_hook(visualize_activations)\n",
        "    input0, label = testset[index[ind]]\n",
        "    input = input0.reshape(1, 1, 32, 32)\n",
        "    output = qat(input)\n",
        "    for name, model in qat.named_children(): model.profile_activations = False \n",
        "    \n",
        "\n",
        "    np.savetxt('./activations/img{}/input.csv'.format(ind), input.cpu().data.numpy().reshape(-1), delimiter=',')\n",
        "    np.savetxt('./activations/img{}/output.csv'.format(ind), output.cpu().data.numpy().reshape(-1).astype(int), delimiter=',')\n",
        "    zf.write('./activations/img{}/input.csv'.format(ind))\n",
        "    zf.write('./activations/img{}/output.csv'.format(ind))\n",
        "    \n",
        "    opDict = {\n",
        "        'conv1': (qat.conv1.inAct, qat.conv1.outAct),\n",
        "        'maxpool2': (qat.maxpool2.inAct, qat.maxpool2.outAct),\n",
        "        'conv3': (qat.conv3.inAct, qat.conv3.outAct),\n",
        "        'maxpool4': (qat.maxpool4.inAct, qat.maxpool4.outAct),\n",
        "        'conv5': (qat.conv5.inAct, qat.conv5.outAct),\n",
        "        'fc6': (qat.fc6.inAct, qat.fc6.outAct),\n",
        "        'output': (qat.output.inAct, qat.output.outAct)\n",
        "    }\n",
        "    \n",
        "    for key in opDict:\n",
        "        if not os.path.exists('./activations/img{}/{}'.format(ind, key)):\n",
        "            os.mkdir('./activations/img{}/{}'.format(ind, key))\n",
        "        if(opDict[key][0].type()== \"torch.quantized.QInt8Tensor\" or opDict[key][0].type()== \"torch.quantized.QUInt8Tensor\"):\n",
        "            temp = opDict[key][0].cpu().int_repr()\n",
        "        else:\n",
        "            temp = opDict[key][0].cpu()\n",
        "        if(opDict[key][1].type()== \"torch.quantized.QInt8Tensor\" or opDict[key][1].type()== \"torch.quantized.QUInt8Tensor\"):\n",
        "            temp1 = opDict[key][1].cpu().int_repr()\n",
        "        else:\n",
        "            temp1 = opDict[key][1].cpu()                \n",
        "        np.savetxt('./activations/img{}/{}/input.csv'.format(ind, key), temp.data.numpy().reshape(-1).astype(float), delimiter=',')\n",
        "        np.savetxt('./activations/img{}/{}/output.csv'.format(ind, key), temp1.cpu().data.numpy().reshape(-1).astype(float), delimiter=',')\n",
        "        zf.write('./activations/img{}/{}/input.csv'.format(ind, key))\n",
        "        zf.write('./activations/img{}/{}/output.csv'.format(ind, key))"
      ],
      "metadata": {
        "id": "Jo4BtOL9aXxN"
      },
      "id": "Jo4BtOL9aXxN",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BlOLRLdTJqcm"
      },
      "outputs": [],
      "source": [
        "zf.close()"
      ],
      "id": "BlOLRLdTJqcm"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "42c9bca9"
      },
      "source": [
        "## 2. High-level Function Implementation for Each Layer\n",
        "Implement a high-level functional model for each layer of the CNN, including convolution, pooling, and \n",
        "fully-connected layer with 8-bit quantization of the input activations, output activations, and weights accordingly.\n",
        "* Learn how to use [Numba](https://numba.pydata.org/) to accelerate python functions\n",
        "* Fill in the TODOs in `functional.py` of `nnutils`.\n",
        "    * You must consider `psum_range = (lower_bound, upper_bound)` which controls the precision of partial sums.\n",
        "    * `psum_record_list` will be used in *2. Bit-width of Partial Sums*, so you may leave it alone for now.\n",
        "    \n",
        "### 2.1 Pass all Unit Tests of `OpTestCase`.\n",
        "First, use 32-bit signed integers for the partial sums to pass the unit tests. The accumulation of activations is limited to 32 bits in convolution and fully-connected layers. Clamp the value if it exceeds the minimum or maximum values of the 32-bit signed number.\n",
        "\n",
        "Note that you should implement convolution layers, fully-connected layers, and max-pooling layers with \"nested loops\" by yourself. You are not allowed to use existing functions (e.g., `conv2d` in `numpy` or `pytorch`). Or you will not get any credits. Raise questions when in doubt.\n",
        "\n",
        "There are eight unit tests you need to pass. If you intend to run part of them, follow the steps:\n",
        "```\n",
        "tests = ['test_C1', 'test_C3']\n",
        "suite = unittest.TestSuite(map(OpTestCase, tests))\n",
        "```"
      ],
      "id": "42c9bca9"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install numba==0.55.1 "
      ],
      "metadata": {
        "id": "XKOBIg_HWqdr"
      },
      "id": "XKOBIg_HWqdr",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rtNleN7vAvWA"
      },
      "outputs": [],
      "source": [
        "import unittest\n",
        "\n",
        "class OpTestCase(unittest.TestCase):\n",
        "    \n",
        "    def setUp(self):\n",
        "        bit = 32\n",
        "        self.number_range = (-(2**(bit-1)), 2**(bit-1) - 1)\n",
        "        self.weightsDict, self.scalesDict = getWeightAndScale()\n",
        "        self.max_samples = 100 #100\n",
        "        \n",
        "        \n",
        "    def tearDown(self):\n",
        "        self.weightsDict, self.scalesDict = None, None\n",
        "        self.source = None\n",
        "         \n",
        "    def test_C1(self):\n",
        "        for i in range(self.max_samples):\n",
        "            self.source = \"./activations/img{}/\".format(i)\n",
        "            x = np.loadtxt(self.source+\"/conv1/input.csv\", delimiter=',').astype(int)\n",
        "            x = x.reshape(1, 1, 32, 32)\n",
        "            x, _ = Conv2d(self.number_range, x, self.weightsDict[\"conv1.conv\"], out_channels=6)\n",
        "            x = x.flatten()\n",
        "            x_ = np.loadtxt(self.source+\"/conv1/output.csv\", delimiter=',').astype(int)\n",
        "            self.assertTrue(np.all(x == x_))\n",
        "\n",
        "    def test_ACTQUANT(self):\n",
        "        for i in range(self.max_samples):\n",
        "            self.source = \"./activations/img{}/\".format(i)\n",
        "            x = np.loadtxt(self.source+\"/conv1/output.csv\", delimiter=',').astype(int)\n",
        "            x = ActQuant(x, self.scalesDict[\"conv1.conv\"])\n",
        "            x = ReLU(x).flatten()\n",
        "            x_ = np.loadtxt(self.source+\"/maxpool2/input.csv\", delimiter=',').astype(int)\n",
        "            self.assertTrue(np.all(x == x_))\n",
        "\n",
        "    def test_S2(self):\n",
        "        for i in range(self.max_samples):\n",
        "            self.source = \"./activations/img{}/\".format(i)\n",
        "            x = np.loadtxt(self.source+\"/maxpool2/input.csv\", delimiter=',').astype(int)\n",
        "            x = x.reshape(1, 6, 28, 28)\n",
        "            x = MaxPool2d(x).flatten()\n",
        "            x_ = np.loadtxt(self.source+\"/maxpool2/output.csv\", delimiter=',').astype(int)\n",
        "            self.assertTrue(np.all(x == x_))\n",
        "    \n",
        "    def test_C3(self):\n",
        "        for i in range(self.max_samples):\n",
        "            self.source = \"./activations/img{}/\".format(i)         \n",
        "            x = np.loadtxt(self.source+\"/conv3/input.csv\", delimiter=',').astype(int)\n",
        "            x = x.reshape(1, 6, 14, 14)\n",
        "            x, _ = Conv2d(self.number_range, x, self.weightsDict[\"conv3.conv\"], out_channels=16)\n",
        "            x = x.flatten()\n",
        "            x_ = np.loadtxt(self.source+\"/conv3/output.csv\", delimiter=',').astype(int)\n",
        "            self.assertTrue(np.all(x == x_))\n",
        "    \n",
        "    def test_S4(self):\n",
        "        for i in range(self.max_samples):\n",
        "            self.source = \"./activations/img{}/\".format(i)         \n",
        "            x = np.loadtxt(self.source+\"/maxpool4/input.csv\", delimiter=',').astype(int)\n",
        "            x = x.reshape(1, 16, 10, 10)\n",
        "            x = MaxPool2d(x).flatten()\n",
        "            x_ = np.loadtxt(self.source+\"/maxpool4/output.csv\", delimiter=',').astype(int)\n",
        "            self.assertTrue(np.all(x == x_))\n",
        "            \n",
        "    def test_C5(self):\n",
        "        for i in range(self.max_samples):\n",
        "            self.source = \"./activations/img{}/\".format(i)             \n",
        "            x = np.loadtxt(self.source+\"/conv5/input.csv\", delimiter=',').astype(int)\n",
        "            x = x.reshape(1, 16, 5, 5)\n",
        "            x, _ = Conv2d(self.number_range, x, self.weightsDict[\"conv5.conv\"], out_channels=120)\n",
        "            x = x.flatten()\n",
        "            x_ = np.loadtxt(self.source+\"/conv5/output.csv\", delimiter=',').astype(int)\n",
        "            self.assertTrue(np.all(x == x_))\n",
        "    \n",
        "    def test_F6(self):\n",
        "        for i in range(self.max_samples):\n",
        "            self.source = \"./activations/img{}/\".format(i)             \n",
        "            x = np.loadtxt(self.source+\"/fc6/input.csv\", delimiter=',').astype(int)\n",
        "            x = x.reshape(1, 120)\n",
        "            x, _ = Linear(self.number_range, x, self.weightsDict[\"fc6.fc\"])\n",
        "            x_ = np.loadtxt(self.source+\"/fc6/output.csv\", delimiter=',')\n",
        "            self.assertTrue(np.all(x == x_))\n",
        "            \n",
        "    def test_OUTPUT(self):\n",
        "        for i in range(1,self.max_samples):\n",
        "            self.source = \"./activations/img{}/\".format(i)             \n",
        "            x = np.loadtxt(self.source+\"/output/input.csv\", delimiter=',').astype(int)\n",
        "            x = x.reshape(1, 84)\n",
        "            x, _ = Linear(self.number_range, x, self.weightsDict[\"output.fc\"], self.weightsDict[\"outputBias\"])\n",
        "            x_ = np.loadtxt(self.source+\"/output/output.csv\", delimiter=',')\n",
        "            self.assertTrue(np.all(x == x_))\n"
      ],
      "id": "rtNleN7vAvWA"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TB-3h1RzM-1G"
      },
      "outputs": [],
      "source": [
        "import numba as nb\n",
        "import json\n",
        "\n",
        "@nb.jit()\n",
        "def MaxPool2d(x, kernel_size=2, stride=2):\n",
        "    N, C, H, W = x.shape\n",
        "    x_out = np.zeros((N, C, int(((H-kernel_size)/stride)+1),\n",
        "                     int((W-kernel_size)/stride + 1)), dtype='int32')\n",
        "    # TODO\n",
        "    \n",
        "    return x_out\n",
        "\n",
        "\n",
        "@nb.jit()\n",
        "def ReLU(x):\n",
        "    # TODO\n",
        "    \n",
        "    return x\n",
        "\n",
        "\n",
        "@nb.jit()\n",
        "def Linear(psum_range, x, weights, weightsBias=None, psum_record=False):\n",
        "  psum_record_list = [np.complex64(x) for x in range(0)]\n",
        "  H, W = x.shape\n",
        "  C = weights.shape[0]\n",
        "  x_out = np.zeros((H, C))\n",
        "  # TODO\n",
        "\n",
        "  return x_out, psum_record_list\n",
        "\n",
        "\n",
        "@nb.jit()\n",
        "def Conv2d(psum_range, x, weights, out_channels, kernel_size=5, stride=1, bias=False, psum_record=False):\n",
        "    psum_record_list = [np.complex64(x) for x in range(0)]\n",
        "    N, C, H, W = x.shape\n",
        "    x_out = np.zeros((N, out_channels, int(((H-kernel_size)/stride)+1),\n",
        "                     int((W-kernel_size)/stride + 1)))\n",
        "    # TODO\n",
        "    \n",
        "\n",
        "    return x_out, psum_record_list\n",
        "\n",
        "\n",
        "def ActQuant(x, scale, shiftbits=16):\n",
        "    # TODO\n",
        "\n",
        "    return x\n"
      ],
      "id": "TB-3h1RzM-1G"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "87b1c981"
      },
      "outputs": [],
      "source": [
        "# tests = ['test_C1']\n",
        "# suite = unittest.TestSuite(map(OpTestCase, tests))\n",
        "suite = unittest.TestLoader().loadTestsFromTestCase(OpTestCase)\n",
        "unittest.TextTestRunner(verbosity=2).run(suite)"
      ],
      "id": "87b1c981"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7c623abf"
      },
      "source": [
        "### 2.2 Reconstruct the LeNet in HW1\n",
        "* Fill in the TODO in `forward()` of `LeNet`.\n",
        "* Test the model with the test dataset. There should be no accuracy degradation if you have done everything correctly."
      ],
      "id": "7c623abf"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e5p17sYm5ZN7"
      },
      "outputs": [],
      "source": [
        "class LeNet:\n",
        "\n",
        "    def __init__(self, psum_range_dict):\n",
        "        self.psum_range = psum_range_dict\n",
        "        self.weightsDict, self.scalesDict = getWeightAndScale()\n",
        "        self.psum_record_dict = {}\n",
        "\n",
        "    def forward(self, x, psum_record=False):\n",
        "      # TODO\n",
        "      # You should get the record of partial sums by `x, self.psum_record_dict['c1'] = Conv2d(...)`.\n",
        "      \n",
        "      \n",
        "      return x"
      ],
      "id": "e5p17sYm5ZN7"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BAKPeqz65wpG"
      },
      "outputs": [],
      "source": [
        "def test(model, dataloader: DataLoader, max_samples=None):\n",
        "    cnt = 0\n",
        "    total = 0\n",
        "    n_inferences = 0\n",
        "    for i, data in enumerate(dataloader):\n",
        "\n",
        "        images, labels = data[0].numpy(), data[1].numpy()\n",
        "        y = model.forward(images)\n",
        "\n",
        "        y = np.argmax(y, axis=1)\n",
        "        cnt = cnt + np.count_nonzero((labels == y) == True)\n",
        "        total += images.shape[0]\n",
        "\n",
        "        if max_samples:\n",
        "            n_inferences += images.shape[0]\n",
        "            if n_inferences >= max_samples:\n",
        "                break\n",
        "\n",
        "    print(\"Accuracy: {}%\".format(cnt/total*100))\n",
        "    return cnt/total*100"
      ],
      "id": "BAKPeqz65wpG"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2639da05"
      },
      "outputs": [],
      "source": [
        "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
        "                                         shuffle=False, num_workers=2)\n",
        "\n",
        "def run_LeNet(n_bit, max_samples = None):\n",
        "    number_range = (-(2**(n_bit-1)), 2**(n_bit-1) - 1)\n",
        "    print(\"bit:\", n_bit)\n",
        "    print(\"bit-width range:\",number_range)\n",
        "\n",
        "    psum_range = {\n",
        "        'c1': number_range,\n",
        "        'c3': number_range,\n",
        "        'c5': number_range,\n",
        "        'f6': number_range,\n",
        "        'output': number_range\n",
        "    }\n",
        "\n",
        "    model = LeNet(psum_range)\n",
        "\n",
        "    return test(model, testloader)\n",
        "\n",
        "run_LeNet(n_bit = 32)"
      ],
      "id": "2639da05"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8d44e4d9"
      },
      "source": [
        "## 3. Bit-width of Partial Sums\n",
        "### 3.1 Question: Find the minimum bit-width of partial sums for all layers with the highest accuracy\n",
        "1. Use matplotlib to plot \"Test Accuracy(%)\" versus \"Bit-width of Partial Sums\" for \"Bit-width of Partial Sums\" in $[2, 32]$ by `matplotlib.pyplot.plot()`.\n",
        "    * [Plot with matplotlib](https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.plot.html).\n",
        "2. What is the smallest bit-width of partial sums that maintains the same accuracy from the previous plot?"
      ],
      "id": "8d44e4d9"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "90fd587c"
      },
      "source": [
        "### 3.1 Answers\n",
        "<font color='red'>Write your answers here.</font>\n",
        "1. ...\n",
        "2. ..."
      ],
      "id": "90fd587c"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3c93f393"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "acc = []\n",
        "for i in range(1, 17):\n",
        "    acc.append(run_LeNet(i*2))\n",
        "    \n",
        "# TODO   \n"
      ],
      "id": "3c93f393"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6127ac58"
      },
      "source": [
        "### 3.2 Question: Find the minimum bit-width of partial sums for each layer with the highest accuracy\n",
        "1. Plot the distribution of partial sums of each quantized layer in the CNN with the MNIST test dataset. Write down the min, max, and standard deviation for each layer. \n",
        "    * Check the TODO in `LeNet` of `LeNetModel`. You should save all partial sums to the dictionary, `psum_record_dict`.\n",
        "    * We can get this dictionary after running the model with the first image in the test dataset by `model.psum_record_dict`.\n",
        "2. Determine the minimum bit-width of partial sums in each layer without hurting the accuracy. \n",
        "    * Fill in the TODO to see if the accuracy is still the same.\n",
        "    * Show the accuracy after doing so."
      ],
      "id": "6127ac58"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4892fb04"
      },
      "source": [
        "### 3.2 Answers\n",
        "<font color='red'>Write your answers here.</font>\n",
        "1. ...\n",
        "2. ..."
      ],
      "id": "4892fb04"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "80d07474"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "n_bit = 32\n",
        "number_range = (-(2**(n_bit-1)), 2**(n_bit-1) - 1)\n",
        "print(\"bit:\", n_bit)\n",
        "print(\"bit-width range:\",number_range)\n",
        "\n",
        "psum_range = {\n",
        "    'c1': number_range,\n",
        "    'c3': number_range,\n",
        "    'c5': number_range,\n",
        "    'f6': number_range,\n",
        "    'output': number_range\n",
        "}\n",
        "\n",
        "model = LeNet(psum_range)\n",
        "\n",
        "image = np.expand_dims(testset[0][0], axis=0)\n",
        "_ = model.forward(image, psum_record = True)\n",
        "\n",
        "# TODO\n",
        "# Plot the distribution of partial sums of each quantized layer in the CNN\n"
      ],
      "id": "80d07474"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d1d17e5f"
      },
      "outputs": [],
      "source": [
        "# TODO\n",
        "# Test your model with those Bit-widths you choose\n",
        "psum_range = {\n",
        "    'c1': ...,\n",
        "    'c3': ...,\n",
        "    'c5': ...,\n",
        "    'f6': ...,\n",
        "    'output': ...\n",
        "}\n",
        "\n",
        "model = LeNet(psum_range)\n",
        "\n",
        "_ = test(model, testloader)\n"
      ],
      "id": "d1d17e5f"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f718967b"
      },
      "source": [
        "## 4. Evaluation: Energy Model\n",
        "### 4.1 Question: Evaluate these two approaches based on the following energy model:\n",
        "$$E_w = s_{mul}\\times N_{mul} + s_{add}\\times N_{add},$$\n",
        "$$s_{mul} = \\alpha\\times \\left(\\frac{B_{mul}}{8}\\right)^2,\\ \\alpha = 64,$$\n",
        "$$s_{add} = \\beta\\times B_{add}, \\ \\beta=1,$$\n",
        "The variables $N_{mul}$ and $N_{add}$ represent the number of multiplications and additions in your dataflow, respectively. It's possible to calculate the $N_{mul}$ and $N_{add}$ of each layer by hand. The variables $B_{mul}$ and $B_{add}$ denote the bit-widths of multiplier and adder, respectively. The constants α and β are provided to model the energy scaling factor of multiplication and addition, respectively. Additionally, $s_{mul}$ represents the energy cost per multiplication, which is proportional to the square of the multiplier’s bit-width. On the other hand, $s_{add}$ denotes the energy cost per addition, which is linearly proportional to the adder’s bit-width. For instance, in our estimation model, a 4-bit multiplier has an energy cost per multiplication of 16, which is computed as 64 x (4/8)^2.\n",
        "* You must accumulate the energy layer by layer to obtain the overall $E_w$, if each layer has a  different $B_{mul}$ or $B_{add}$.\n",
        "* We only consider convolution and fully-connected operations, ignoring pooling and ReLU operations in this energy model.\n",
        "* Disclaimer: Note that this energy model is artificial and oversimplified. DO NOT apply it to your research work.\n",
        "\n",
        "1. Calculate the overall $E_w$ with minimum bit-width for the setup of 3.1.\n",
        "2. Calculate the energy layer by layer and also the overall $E_w$ for the setup of 3.2."
      ],
      "id": "f718967b"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5168ea53"
      },
      "source": [
        "### 4.1 Answers\n",
        "<font color='red'>Write your answers here.</font>\n",
        "1. ...\n",
        "2. ..."
      ],
      "id": "5168ea53"
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}